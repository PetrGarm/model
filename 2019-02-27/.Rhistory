head(usconsumption)
# The choice of the order of the reduced form model
# was discussed in practice session 11
var3 <- VAR(usconsumption, p = 3, type = "const")
var_fcst <- forecast(var3, h = 8)
View(var3)
View(var3)
View(var_fcst)
View(var_fcst)
View(var_fcst)
var_fcst$forecast$consumption$mean
View(var_fcst)
View(var_fcst)
var_fcst$forecast$consumption$mean
var_fcst$forecast$income$mean
var_fcst$forecast$consumption
View(var3)
var3[["datamat"]]
head(usconsumption)
autoplot(var_fcst)
causality(var3, 'consumption')
causality(var3, 'income')
# Alternative ways to compute (B_0)^{-1}
Omega_hat <- summary(var3)$covres
chol(Omega_hat)%>%t()
Psi(var3)[,,1]
## VAR estimation: example
library(fpp)
library(vars)
data(usconsumption, package = "fpp")
head(usconsumption)
# The choice of the order of the reduced form model
# was discussed in practice session 11
var3 <- VAR(usconsumption, p = 3, type = "const")
var_fcst <- forecast(var3, h = 8)
View(var3)
View(var3)
View(var_fcst)
View(var_fcst)
View(var_fcst)
var_fcst$forecast$consumption
var_fcst$forecast$consumption$mean
var_fcst$forecast$income$mean
autoplot(var_fcst)
causality(var3, 'consumption')
causality(var3, 'income')
data(usconsumption, package = "fpp")
irf3 <- irf(var3, impulse = "consumption", response = c("consumption",
"income"), n.ahead = 20, cumulative = TRUE)
e = TRUE)
plot(irf3)
## Impulse response functions: code
var3 <- VAR(usconsumption, p = 3, type = "const")
library(vars)
library(fpp)
library(vars)
library(tidyverse)
data(usconsumption, package = "fpp")
head(usconsumption)
## Impulse response functions: code
var3 <- VAR(usconsumption, p = 3, type = "const")
irf3 <- irf(var3, impulse = "consumption", response = c("consumption",
"income"), n.ahead = 20, cumulative = TRUE)
View(irf3)
View(irf3)
plot(irf3)
## Forward error variance decomposition
fevd(var3, n.ahead = 4)
## Change of ordering
usconsumption2 <- usconsumption[, c("income","consumption")]
head(usconsumption2)
var3a <- VAR(usconsumption2, p = 3, type = "const")
irf3a <- irf(var3a, impulse = "consumption", response = c("consumption",
"income"), n.ahead = 20, cumulative = TRUE)
plot(irf3a)
## FEVD with alternative ordering
fevd(var3a, n.ahead = 4)
# Создаем таблицу из созданных переменных
swiss4 <-
# Печатаем таблицу
## Задание 27
swiss4[]
library(readxl)
unemp_rate <- read_excel("D:/Teaching/BAC/WinterSchool/2019/Seminar3/unemp_rate.xlsx")
View(unemp_rate)
write.csv(unemp_rate, "unemp_rate.csv")
getwd()
unemp_rate <- read.csv("~/unemp_rate.csv")
View(unemp_rate)
install.packages("azbuka")
## Задание 30
lower_mortality <-swiss[,swiss$Infant.Mortality<20]
swiss
swiss
swiss <- swiss
lower_mortality <-subset(swiss,swiss$Infant.Mortality<20)
lower_mortality <-swiss[,"Infant.Mortality"<20]
## Импорт данных из внешнего источника(2)
library(readr) # не нужно выполнять, если `tidyverse` уже присоединен.
data1 <- read_csv("mydata.csv")
## Визуализация данных: первый шаг
head(LifeCycleSavings, 3)
##  Визуализация данных: диаграмма рассеяния
ggplot(data = LifeCycleSavings) +
geom_point(mapping = aes(x = dpi, y = sr))
library(tidyverse)
##  Визуализация данных: диаграмма рассеяния
ggplot(data = LifeCycleSavings) +
geom_point(mapping = aes(x = dpi, y = sr))
## Визуализация: выделение подмножеств цветом
ggplot(data = LifeCycleSavings) +
geom_point(mapping = aes(x = dpi, y = sr, color = pop15))
## Визулизация: выделение подмножеств размером маркера.
ggplot(data = LifeCycleSavings) +
geom_point(mapping = aes(x = dpi, y = sr, size = pop75))
? read_csv
?read.csv
# Задание 6
z <- 0
i <- 0
while (z<15) {
i <- i + 1
z <- rnorm(1, i, 2)
print(z)
}
# Задание 6
z <- 0
i <- 0
# Задание 7
a = rnorm(1,0,3)
if(a<-2)|(a>0){
print('yes')
}else{
print('no')
}
# Задание 7
a = rnorm(1,0,3)
if ((a<-2)||(a>0)){
print('yes')
}else{
print('no')
}
library(readr)
piazza_ws2019_roster <- read_csv("D:/Teaching/BAC/WinterSchool/2019/piazza-ws2019_roster.csv")
View(piazza_ws2019_roster)
library(tidyverse)
emails<- select(piazza_ws2019_roster,email)
write_excel_csv(emails,"emails")
getwd()
help(euretail)
library(forecast)
help(data = euretail)
euretail
library(fpp)
euretail
data(package =  fpp)
data(package = "fpp")
## Пример с сезонной моделью ARIMA
autoplot(euretail)+xlab("Year") + ylab("Retail index") # из пакета fpp
euretail<-euretail
head(euretail)
head(euretail)
ggAcf(euretail)
grid.arrange(ggAcf(euretail),ggPacf(euretail), nrow = 2)
library(gridExtra)
grid.arrange(ggAcf(euretail),ggPacf(euretail), nrow = 2)
grid.arrange(ggAcf(diff(euretail)),ggPacf(diff(euretail)), nrow = 2)
sd_eure <- diff(euretail)
sd_eure <- diff(euretail, lag = 4)
autoplot(sd_eure)
grid.arrange(ggAcf(sd_eure),ggPacf(sd_eure), nrow = 2)
grid.arrange(ggAcf(sd_eure),ggPacf(sd_eure), nrow = 2)
sdd_eure <- diff(sd)
sdd_eure <- diff(sd, lag = 1)
sdd_eure <- diff(sd_eure)
autoplot(sdd_eure)
grid.arrange(ggAcf(sdd_eure),ggPacf(sdd_eure), nrow = 2)
autoplot(residuals(fit1))
fit1 <- Arima(euretail,order = c(0,1,1), seasonal = c(0,1,1))
autoplot(residuals(fit1))
grid.arrange(residuals(fit1),residuals(fit1), nrow = 2)
grid.arrange(ggAcf(residuals(fit1)),ggPacf(residuals(fit1)), nrow = 2)
A=matrix(rep(0,16),nrow = 4)
for(i in 0:3){
for(j in 0:3){
model <- Arima(euretail,order = c(i,1,j), seasonal = c(0,1,1))
A[i+1,j+1] = model$aicc
}
}
A
best_fit <- Arima(euretail,order = c(0,1,3), seasonal = c(0,1,1))
grid.arrange(ggAcf(residuals(best_fit)),ggPacf(residuals(best_fit)), nrow = 2)
checkresiduals(best_fit)
Box.test(residuals(best_fit), lag = 12, fitdf = 4)
Box.test(residuals(best_fit), lag = 12, fitdf = 4, type = "Lj")
Box.test(residuals(best_fit), lag = 12, fitdf = 4, type = "Lj")
checkresiduals(best_fit)
Box.test(residuals(best_fit), lag = 8, fitdf = 4, type = "Lj")
checkresiduals(best_fit)
checkresiduals(best_fit, plot = TRUE )
auto.arima(euretail)
rm(euretail)
autoplot(euretail)+xlab("Year") + ylab("Retail index") # из пакета fpp
head(euretail)
grid.arrange(ggAcf(euretail),ggPacf(euretail), nrow = 2)
grid.arrange(ggAcf(diff(euretail)),ggPacf(diff(euretail)), nrow = 2)
sd_eure <- diff(euretail, lag = 4)
autoplot(sd_eure)
grid.arrange(ggAcf(sd_eure),ggPacf(sd_eure), nrow = 2)
sdd_eure <- diff(sd_eure)
autoplot(sdd_eure)
grid.arrange(ggAcf(sdd_eure),ggPacf(sdd_eure), nrow = 2)
fit1 <- Arima(euretail,order = c(0,1,1), seasonal = c(0,1,1))
autoplot(residuals(fit1))
grid.arrange(ggAcf(residuals(fit1)),ggPacf(residuals(fit1)), nrow = 2)
A=matrix(rep(0,16),nrow = 4)
for(i in 0:3){
for(j in 0:3){
model <- Arima(euretail,order = c(i,1,j), seasonal = c(0,1,1))
A[i+1,j+1] = model$aicc
}
}
A
best_fit <- Arima(euretail,order = c(0,1,3), seasonal = c(0,1,1))
grid.arrange(ggAcf(residuals(best_fit)),ggPacf(residuals(best_fit)), nrow = 2)
Box.test(residuals(best_fit), lag = 8, fitdf = 4, type = "Lj")
checkresiduals(best_fit)
auto.arima(euretail)
## Меры точности прогноза: код
US_inv <- read_csv("US_investment.dat")
library(readxl)
log_cpi_data <- read_excel("D:/Teaching/BAC/WinterSchool/2019/Day3/Morning/log_cpi_data.xlsx",
col_names = FALSE)
View(log_cpi_data)
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)
library(tidyverse)
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)
log_cpi_data <- read_excel("D:/Teaching/BAC/WinterSchool/2019/Day3/Morning/log_cpi_data.xlsx",
+     col_names = FALSE)
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)+
%>% window(end=c(2016,12))
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)  %>% window(end=c(2016,12))
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)  %>%
window(end=c(2016,12))
head(data)
data <- dplyr::select(log_cpi_data,2) %>% ts(start = c(1999,1), freq = 12)  %>%
window(end=c(2016,12))
View(data)
head(data)
data_ts <- ts(log_cpi_data,start = c(1999,1), freq = 12)
data1<- select(log_cpi_data, 2)
data_ts <- ts(data1,start = c(1999,1), freq = 12)
head(data_ts)
## Оценка VAR: пример
library(fpp)
library(vars)
data(usconsumption, package = "fpp")
head(usconsumption)
autoplot(usconsumption[,1])
autoplot(usconsumption[,2])
head(usconsumption)
grid.arrange(ggAcf(usconsumption[,1]), ggPacf(usconsumption[,1]))
library(gridExtra)
grid.arrange(ggAcf(usconsumption[,1]), ggPacf(usconsumption[,1]))
grid.arrange(ggAcf(usconsumption[,2]), ggPacf(usconsumption[,2]))
help(package = "forecast")
source('~/.active-rstudio-document', echo=TRUE)
library(tidyverse)
seas(USAccDeaths) %>% autoplot
co2 %>% decompose %>% autoplot
library(ggplot2)
co2 %>% decompose %>% autoplot
nottem %>% stl(s.window='periodic') %>% autoplot
## Not run:
library(seasonal)
library(tidyverse)
seas(USAccDeaths) %>% autoplot
nottem %>% stl(s.window='periodic') %>% autoplot
help(package = "forecast")
help(package = "forecast")
help(package = "forecast")
m <- seas(AirPassengers)
library(seasonal)
install.packages("seasonal")
library(seasonal)
m <- seas(AirPassengers)
plot(m)
plot(m, outliers = FALSE)
plot(m, trend = TRUE)
residplot(m)
residplot(m, outliers = FALSE)
monthplot(m)
# use standard R functions to analyze "seas" models
pacf(resid(m))
spectrum(diff(resid(m)))
plot(density(resid(m)))
qqnorm(resid(m))
library(ggplot2)
co2 %>% decompose %>% autoplot
nottem %>% stl(s.window='periodic') %>% autoplot
## Not run:
library(seasonal)
library(tidyverse)
seas(USAccDeaths) %>% autoplot
help(package = "forecast")
install.packages("GVAR", repos="http://R-Forge.R-project.org")
setwd("D:/Research/Kassandra/model/2019-02-27")
data
data
setwd("D:/Research/Kassandra/model/2019-02-27")
library(tidyverse) # data manipulation
library(rio) # import - export data
library(tsibble) # ts data frames
#library(fable) # forecasting models
library(forecast) # forecasting models
library(lubridate) # working with dates
library(glmnet) # lasso
library(naniar) # missing values visualization
# library(fasster) # fasster model
library(ranger) # random forest
library(stringr) # character variables
library(rlang) # шаманство с бум-бум!
library(readxl) # чтение экселевских файлов
library(kassandr)
Sys.setlocale("LC_TIME", "C")
start_date = ymd("2011-10-01")
I_ipc = import("data_snapshot/I_ipc_converted.csv")
I_ipc_tsibble = mutate(I_ipc, date = yearmonth(date)) %>% as_tsibble(index = date)
rus_m_full_stable = filter(I_ipc_tsibble, date >= start_date)
rus_m_full_stable %>% tail()
rus_m_full_stable %>% head()
proportion_test = 0.2 # доля ряда, используемая для оценки качества прогнозов
nobs_full = nrow(rus_m_full_stable)
nobs_test = round(proportion_test * nobs_full)
window_type = "sliding" # "sliding" or "stretching" as in tsibble
dates_test = tail(rus_m_full_stable$date, nobs_test)
h_all = 1:6
model_fun_tibble = tribble(~model_fun, ~h_agnostic, ~forecast_extractor,
"ets_fun", TRUE, "uni_model_2_scalar_forecast",
"tbats_fun", TRUE, "uni_model_2_scalar_forecast",
"arima_fun", TRUE, "uni_model_2_scalar_forecast",
"arima11_fun", TRUE, "uni_model_2_scalar_forecast")
cv_results = prepare_model_list(h_all = h_all, model_fun_tibble = model_fun_tibble, dates_test = dates_test,
window_type = window_type, series_data = rus_m_full_stable)
devtools::install_github("kassandra-ru/kassandr")
devtools::install_github("kassandra-ru/kassandr")
library(tidyverse) # data manipulation
library(rio) # import - export data
library(tsibble) # ts data frames
#library(fable) # forecasting models
library(forecast) # forecasting models
library(lubridate) # working with dates
library(glmnet) # lasso
library(naniar) # missing values visualization
# library(fasster) # fasster model
library(ranger) # random forest
library(stringr) # character variables
library(rlang) # шаманство с бум-бум!
library(readxl) # чтение экселевских файлов
library(kassandr)
Sys.setlocale("LC_TIME", "C")
start_date = ymd("2011-10-01")
I_ipc = import("data_snapshot/I_ipc_converted.csv")
I_ipc_tsibble = mutate(I_ipc, date = yearmonth(date)) %>% as_tsibble(index = date)
rus_m_full_stable = filter(I_ipc_tsibble, date >= start_date)
rus_m_full_stable %>% tail()
rus_m_full_stable %>% head()
proportion_test = 0.2 # доля ряда, используемая для оценки качества прогнозов
nobs_full = nrow(rus_m_full_stable)
nobs_test = round(proportion_test * nobs_full)
window_type = "sliding" # "sliding" or "stretching" as in tsibble
dates_test = tail(rus_m_full_stable$date, nobs_test)
h_all = 1:6
model_fun_tibble = tribble(~model_fun, ~h_agnostic, ~forecast_extractor,
"ets_fun", TRUE, "uni_model_2_scalar_forecast",
"tbats_fun", TRUE, "uni_model_2_scalar_forecast",
"arima_fun", TRUE, "uni_model_2_scalar_forecast",
"arima11_fun", TRUE, "uni_model_2_scalar_forecast")
cv_results = prepare_model_list(h_all = h_all, model_fun_tibble = model_fun_tibble, dates_test = dates_test,
window_type = window_type, series_data = rus_m_full_stable)
cv_results_new = estimate_and_forecast(cv_results)
mae_table = calculate_mae_table(cv_results_new)
mae_table %>% tail()
write_csv(mae_table, "mae_table_cpi.csv")
the_forecasts = prepare_model_list2(h_all = h_all, model_fun_tibble = model_fun_tibble, series_data = rus_m_full_stable)
the_forecasts_new = estimate_and_forecast(the_forecasts)
only_numbers = select(the_forecasts_new, date, h, model_fun, point_forecast)
write_csv(only_numbers, path = "forecasts_cpi.csv")
tab6b = import("data_snapshot/tab6b_converted.csv")
tab6b_tsibble = mutate(tab6b, date = yearquarter(date)) %>% as_tsibble(index = date)
tab6b_tsibble = rename(tab6b_tsibble, gdp_real_2016_price = value) %>% mutate(gdp_rate = (gdp_real_2016_price - lag(gdp_real_2016_price, 4))/lag(gdp_real_2016_price, 4))
tab6b_tsibble %>% head()
tab6b_tsibble %>% tail()
start_date = ymd("2012-01-01")
rus_q_full_stable = tab6b_tsibble %>% rename(value = gdp_rate) %>% filter(date >= start_date)
proportion_test = 0.2 # доля ряда, используемая для оценки качества прогнозов
nobs_full = nrow(rus_q_full_stable)
nobs_test = round(proportion_test * nobs_full)
window_type = "sliding" # "sliding" or "stretching" as in tsibble
dates_test = tail(rus_q_full_stable$date, nobs_test)
h_all = 1:3
model_fun_tibble = tribble(~model_fun, ~h_agnostic, ~forecast_extractor,
"ets_fun", TRUE, "uni_model_2_scalar_forecast",
"tbats_fun", TRUE, "uni_model_2_scalar_forecast",
"arima_fun", TRUE, "uni_model_2_scalar_forecast",
"arima11_fun", TRUE, "uni_model_2_scalar_forecast")
cv_results = prepare_model_list(h_all = h_all, model_fun_tibble = model_fun_tibble, dates_test = dates_test,
window_type = window_type, series_data = rus_q_full_stable)
cv_results_new = estimate_and_forecast(cv_results)
mae_table = calculate_mae_table(cv_results_new)
mae_table
write_csv(mae_table, "mae_table_gdp_rate_real.csv")
the_forecasts = prepare_model_list2(h_all = h_all, model_fun_tibble = model_fun_tibble, series_data = rus_q_full_stable)
the_forecasts_new = estimate_and_forecast(the_forecasts)
only_numbers = select(the_forecasts_new, date, h, model_fun, point_forecast)
only_numbers
write_csv(only_numbers, path = "forecasts_gdp_rate_real.csv")
library(tidyverse)
library(tidyr)
library(rio)
mae_table = import("mae_table_cpi.csv")
mae_post = mutate(mae_table, h = case_when(h == 1 ~ "1 месяц",
h == 2 ~ "2 месяца",
h == 3 ~ "3 месяца",
h == 4 ~ "4 месяца",
h == 5 ~ "5 месяцев",
h == 6 ~ "6 месяцев"), mae = round(mae, 2))
mae_wide = spread(mae_post, key = model_fun, value = mae)
write_csv2_cp1251(mae_wide, "mae_cpi_wide.csv")
forecast_table = import("forecasts_cpi.csv")
forecast_post = mutate(forecast_table, point_forecast = round(point_forecast, 2)) %>%
mutate(date = case_when(date == "2018-09-01" ~ "сентябрь 2018",
date == "2018-10-01" ~ "октябрь 2018",
date == "2018-11-01" ~ "ноябрь 2018",
date == "2018-12-01" ~ "декабрь 2018",
date == "2019-01-01" ~ "январь 2019",
date == "2019-02-01" ~ "февраль 2019",
date == "2019-03-01" ~ "март 2019",
date == "2019-04-01" ~ "апрель 2019",
date == "2019-05-01" ~ "май 2019",
date == "2019-06-01" ~ "июнь 2019"
))
forecast_wide = spread(forecast_post, key = model_fun, value = point_forecast) %>% arrange(h) %>% select(-h)
write_csv2_cp1251(forecast_wide, "forecast_cpi_wide.csv")
mae_table = import("mae_table_gdp_rate_real.csv")
mae_post = mutate(mae_table, h = case_when(h == 1 ~ "1 квартал",
h == 2 ~ "2 квартала",
h == 3 ~ "3 квартала",
h == 4 ~ "4 квартала",
h == 5 ~ "5 кварталов",
h == 6 ~ "6 кварталов"), mae = round(mae, 4))
mae_wide = spread(mae_post, key = model_fun, value = mae)
write_csv2_cp1251(mae_wide, "mae_gdp_wide.csv")
forecast_table = import("forecasts_gdp_rate_real.csv")
forecast_post = mutate(forecast_table, point_forecast = round(point_forecast, 3)) %>%
mutate(date = case_when(date == "2018-10-01" ~ "IV квартал 2018",
date == "2019-01-01" ~ "I квартал 2019",
date == "2019-04-01" ~ "II квартал 2019"))
forecast_wide = spread(forecast_post, key = model_fun, value = point_forecast) %>% arrange(h) %>% select(-h)
write_csv2_cp1251(forecast_wide, "forecast_gdp_wide.csv")
library(tidyverse)
library(tidyr)
library(rio)
mae_table = import("mae_table_cpi.csv")
mae_post = mutate(mae_table, h = case_when(h == 1 ~ "1 месяц",
h == 2 ~ "2 месяца",
h == 3 ~ "3 месяца",
h == 4 ~ "4 месяца",
h == 5 ~ "5 месяцев",
h == 6 ~ "6 месяцев"), mae = round(mae, 2))
mae_wide = spread(mae_post, key = model_fun, value = mae)
write_csv2_cp1251(mae_wide, "mae_cpi_wide.csv")
forecast_table = import("forecasts_cpi.csv")
forecast_post = mutate(forecast_table, point_forecast = round(point_forecast, 2)) %>%
mutate(date = case_when(date == "2018-09-01" ~ "сентябрь 2018",
date == "2018-10-01" ~ "октябрь 2018",
date == "2018-11-01" ~ "ноябрь 2018",
date == "2018-12-01" ~ "декабрь 2018",
date == "2019-01-01" ~ "январь 2019",
date == "2019-02-01" ~ "февраль 2019",
date == "2019-03-01" ~ "март 2019",
date == "2019-04-01" ~ "апрель 2019",
date == "2019-05-01" ~ "май 2019",
date == "2019-06-01" ~ "июнь 2019",
date == "2019-07-01" ~ "июль 2019",
date == "2019-08-01" ~ "август 2019"
))
forecast_wide = spread(forecast_post, key = model_fun, value = point_forecast) %>% arrange(h) %>% select(-h)
write_csv2_cp1251(forecast_wide, "forecast_cpi_wide.csv")
forecast_wide = spread(forecast_post, key = model_fun, value = point_forecast) %>% arrange(h) %>% select(-h)
write_csv2_cp1251(forecast_wide, "forecast_cpi_wide.csv")
mae_table = import("mae_table_gdp_rate_real.csv")
mae_post = mutate(mae_table, h = case_when(h == 1 ~ "1 квартал",
h == 2 ~ "2 квартала",
h == 3 ~ "3 квартала",
h == 4 ~ "4 квартала",
h == 5 ~ "5 кварталов",
h == 6 ~ "6 кварталов"), mae = round(mae, 4))
mae_wide = spread(mae_post, key = model_fun, value = mae)
write_csv2_cp1251(mae_wide, "mae_gdp_wide.csv")
forecast_table = import("forecasts_gdp_rate_real.csv")
forecast_post = mutate(forecast_table, point_forecast = round(point_forecast, 3)) %>%
mutate(date = case_when(date == "2018-10-01" ~ "IV квартал 2018",
date == "2019-01-01" ~ "I квартал 2019",
date == "2019-04-01" ~ "II квартал 2019",
date == "2019-07-01" ~ "III квартал 2019",
date == "2019-10-01" ~ "IV квартал 2019"
))
forecast_wide = spread(forecast_post, key = model_fun, value = point_forecast) %>% arrange(h) %>% select(-h)
write_csv2_cp1251(forecast_wide, "forecast_gdp_wide.csv")
help(package = kassandr)
ranger_fun
